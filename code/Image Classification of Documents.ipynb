{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification of Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "To prepare your environment, you need to install some packages and enter credentials for the Watson services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Install the necessary packages\n",
    "You need the latest versions of these packages:\n",
    "python-swiftclient: is a python client for the Swift API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install IBM Cloud Object Storage Client: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install ibm-cos-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now restart the kernel by choosing Kernel > Restart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import packages and libraries\n",
    "Import the packages and libraries that you'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import PIL\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#import ibm_boto3\n",
    "#from botocore.client import Config\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "Add configurable items of the notebook below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Add your service credentials for Object Storage\n",
    "You must create Object Storage service on IBM Cloud. To access data in a file in Object Storage, you need the Object Storage authentication credentials. Insert the Object Storage authentication credentials as credentials_1 in the following cell after removing the current contents in the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials_1 = {\n",
    "    'IBM_API_KEY_ID': '5j3Ot-9_c4Q4qwAAG9IehVYKDg-ovhJ38F95g1frNYGa',\n",
    "    'IAM_SERVICE_ID': 'iam-ServiceId-917d87a5-7c76-4e5e-832f-1871587eaa77',\n",
    "    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT': 'https://iam.ng.bluemix.net/oidc/token',\n",
    "    'BUCKET': 'try1e5849cebfc54c92a72ad6fcde9a73af',\n",
    "    'FILE': 'KnowledgeBase_CodePattern_sample1.docx'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Global Variables\n",
    "Add global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Test_cheque_4.jpg',\n",
       " 'Test_cheque_5.jpg',\n",
       " 'Test_cheque_6.jpg',\n",
       " 'Test_cheque_7.jpg',\n",
       " 'Test_cheque_8.jpg',\n",
       " 'Test_drivinglicense_26.jpg',\n",
       " 'Test_drivinglicense_27.jpg',\n",
       " 'Test_drivinglicense_28.jpg',\n",
       " 'Test_drivinglicense_29.jpg',\n",
       " 'Test_drivinglicense_30.jpg',\n",
       " 'Test_none_15.jpg',\n",
       " 'Test_none_16.jpg',\n",
       " 'Test_none_17.jpg',\n",
       " 'Test_none_18.jpg',\n",
       " 'Test_none_19.jpg',\n",
       " 'Test_pancard_16.jpg',\n",
       " 'Test_pancard_17.jpg',\n",
       " 'Test_pancard_18.jpg',\n",
       " 'Test_pancard_19.jpg',\n",
       " 'Test_pancard_20.jpg',\n",
       " 'Test_passport_27.jpg',\n",
       " 'Test_passport_28.jpg',\n",
       " 'Test_passport_29.jpg',\n",
       " 'Test_passport_30.jpg',\n",
       " 'Test_passport_31.jpg',\n",
       " 'Train_cheque_0.jpg',\n",
       " 'Train_cheque_1.jpg',\n",
       " 'Train_cheque_10.jpg',\n",
       " 'Train_cheque_11.jpg',\n",
       " 'Train_cheque_12.jpg',\n",
       " 'Train_cheque_13.jpg',\n",
       " 'Train_cheque_14.jpg',\n",
       " 'Train_cheque_15.jpg',\n",
       " 'Train_cheque_16.jpg',\n",
       " 'Train_cheque_17.jpg',\n",
       " 'Train_cheque_18.jpg',\n",
       " 'Train_cheque_19.jpg',\n",
       " 'Train_cheque_2.jpg',\n",
       " 'Train_cheque_20.jpg',\n",
       " 'Train_cheque_21.jpg',\n",
       " 'Train_cheque_22.jpg',\n",
       " 'Train_cheque_23.jpg',\n",
       " 'Train_cheque_24.jpg',\n",
       " 'Train_cheque_3.jpg',\n",
       " 'Train_cheque_35.jpg',\n",
       " 'Train_cheque_36.jpg',\n",
       " 'Train_cheque_37.jpg',\n",
       " 'Train_cheque_38.jpg',\n",
       " 'Train_cheque_39.jpg',\n",
       " 'Train_cheque_40.jpg',\n",
       " 'Train_cheque_41.jpg',\n",
       " 'Train_cheque_42.jpg',\n",
       " 'Train_cheque_43.jpg',\n",
       " 'Train_cheque_44.jpg',\n",
       " 'Train_cheque_45.jpg',\n",
       " 'Train_cheque_46.jpg',\n",
       " 'Train_cheque_47.jpg',\n",
       " 'Train_cheque_48.jpg',\n",
       " 'Train_cheque_49.jpg',\n",
       " 'Train_cheque_50.jpg',\n",
       " 'Train_cheque_9.jpg',\n",
       " 'Train_drivinglicense_0.jpg',\n",
       " 'Train_drivinglicense_1.jpg',\n",
       " 'Train_drivinglicense_10.jpg',\n",
       " 'Train_drivinglicense_11.jpg',\n",
       " 'Train_drivinglicense_12.jpg',\n",
       " 'Train_drivinglicense_13.jpg',\n",
       " 'Train_drivinglicense_14.jpg',\n",
       " 'Train_drivinglicense_15.jpg',\n",
       " 'Train_drivinglicense_16.jpg',\n",
       " 'Train_drivinglicense_17.jpg',\n",
       " 'Train_drivinglicense_18.jpg',\n",
       " 'Train_drivinglicense_19.jpg',\n",
       " 'Train_drivinglicense_2.jpg',\n",
       " 'Train_drivinglicense_3.jpg',\n",
       " 'Train_drivinglicense_35.jpg',\n",
       " 'Train_drivinglicense_36.jpg',\n",
       " 'Train_drivinglicense_37.jpg',\n",
       " 'Train_drivinglicense_38.jpg',\n",
       " 'Train_drivinglicense_39.jpg',\n",
       " 'Train_drivinglicense_4.jpg',\n",
       " 'Train_drivinglicense_40.jpg',\n",
       " 'Train_drivinglicense_41.jpg',\n",
       " 'Train_drivinglicense_42.jpg',\n",
       " 'Train_drivinglicense_43.jpg',\n",
       " 'Train_drivinglicense_44.jpg',\n",
       " 'Train_drivinglicense_45.jpg',\n",
       " 'Train_drivinglicense_46.jpg',\n",
       " 'Train_drivinglicense_47.jpg',\n",
       " 'Train_drivinglicense_48.jpg',\n",
       " 'Train_drivinglicense_49.jpg',\n",
       " 'Train_drivinglicense_5.jpg',\n",
       " 'Train_drivinglicense_6.jpg',\n",
       " 'Train_drivinglicense_7.jpg',\n",
       " 'Train_drivinglicense_8.jpg',\n",
       " 'Train_drivinglicense_9.jpg',\n",
       " 'Train_none_0.jpg',\n",
       " 'Train_none_1.jpg',\n",
       " 'Train_none_10.jpg',\n",
       " 'Train_none_11.jpg',\n",
       " 'Train_none_12.jpg',\n",
       " 'Train_none_13.jpg',\n",
       " 'Train_none_14.jpg',\n",
       " 'Train_none_2.jpg',\n",
       " 'Train_none_20.jpg',\n",
       " 'Train_none_21.jpg',\n",
       " 'Train_none_22.jpg',\n",
       " 'Train_none_23.jpg',\n",
       " 'Train_none_24.jpg',\n",
       " 'Train_none_3.jpg',\n",
       " 'Train_none_36.jpg',\n",
       " 'Train_none_37.jpg',\n",
       " 'Train_none_38.jpg',\n",
       " 'Train_none_39.jpg',\n",
       " 'Train_none_4.jpg',\n",
       " 'Train_none_40.jpg',\n",
       " 'Train_none_41.jpg',\n",
       " 'Train_none_42.jpg',\n",
       " 'Train_none_43.jpg',\n",
       " 'Train_none_44.jpg',\n",
       " 'Train_none_45.jpg',\n",
       " 'Train_none_46.jpg',\n",
       " 'Train_none_47.jpg',\n",
       " 'Train_none_48.jpg',\n",
       " 'Train_none_49.jpg',\n",
       " 'Train_none_5.jpg',\n",
       " 'Train_none_50.jpg',\n",
       " 'Train_none_51.jpg',\n",
       " 'Train_none_52.jpg',\n",
       " 'Train_none_53.jpg',\n",
       " 'Train_none_54.jpg',\n",
       " 'Train_none_55.jpg',\n",
       " 'Train_none_6.jpg',\n",
       " 'Train_none_7.jpg',\n",
       " 'Train_none_8.jpg',\n",
       " 'Train_none_9.jpg',\n",
       " 'Train_pancard_0.jpg',\n",
       " 'Train_pancard_1.jpg',\n",
       " 'Train_pancard_10.jpg',\n",
       " 'Train_pancard_11.jpg',\n",
       " 'Train_pancard_12.jpg',\n",
       " 'Train_pancard_13.jpg',\n",
       " 'Train_pancard_14.jpg',\n",
       " 'Train_pancard_15.jpg',\n",
       " 'Train_pancard_2.jpg',\n",
       " 'Train_pancard_21.jpg',\n",
       " 'Train_pancard_22.jpg',\n",
       " 'Train_pancard_23.jpg',\n",
       " 'Train_pancard_24.jpg',\n",
       " 'Train_pancard_3.jpg',\n",
       " 'Train_pancard_35.jpg',\n",
       " 'Train_pancard_36.jpg',\n",
       " 'Train_pancard_37.jpg',\n",
       " 'Train_pancard_38.jpg',\n",
       " 'Train_pancard_39.jpg',\n",
       " 'Train_pancard_4.jpg',\n",
       " 'Train_pancard_40.jpg',\n",
       " 'Train_pancard_41.jpg',\n",
       " 'Train_pancard_42.jpg',\n",
       " 'Train_pancard_43.jpg',\n",
       " 'Train_pancard_44.jpg',\n",
       " 'Train_pancard_45.jpg',\n",
       " 'Train_pancard_46.jpg',\n",
       " 'Train_pancard_47.jpg',\n",
       " 'Train_pancard_48.jpg',\n",
       " 'Train_pancard_49.jpg',\n",
       " 'Train_pancard_5.jpg',\n",
       " 'Train_pancard_50.jpg',\n",
       " 'Train_pancard_51.jpg',\n",
       " 'Train_pancard_52.jpg',\n",
       " 'Train_pancard_6.jpg',\n",
       " 'Train_pancard_7.jpg',\n",
       " 'Train_pancard_8.jpg',\n",
       " 'Train_pancard_9.jpg',\n",
       " 'Train_passport_0.jpg',\n",
       " 'Train_passport_1.jpg',\n",
       " 'Train_passport_10.jpg',\n",
       " 'Train_passport_11.jpg',\n",
       " 'Train_passport_12.jpg',\n",
       " 'Train_passport_13.jpg',\n",
       " 'Train_passport_14.jpg',\n",
       " 'Train_passport_15.jpg',\n",
       " 'Train_passport_16.jpg',\n",
       " 'Train_passport_17.jpg',\n",
       " 'Train_passport_18.jpg',\n",
       " 'Train_passport_19.jpg',\n",
       " 'Train_passport_2.jpg',\n",
       " 'Train_passport_3.jpg',\n",
       " 'Train_passport_35.jpg',\n",
       " 'Train_passport_36.jpg',\n",
       " 'Train_passport_37.jpg',\n",
       " 'Train_passport_38.jpg',\n",
       " 'Train_passport_4.jpg',\n",
       " 'Train_passport_40.jpg',\n",
       " 'Train_passport_41.jpg',\n",
       " 'Train_passport_42.jpg',\n",
       " 'Train_passport_43.jpg',\n",
       " 'Train_passport_44.jpg',\n",
       " 'Train_passport_45.jpg',\n",
       " 'Train_passport_46.jpg',\n",
       " 'Train_passport_47.jpg',\n",
       " 'Train_passport_48.jpg',\n",
       " 'Train_passport_49.jpg',\n",
       " 'Train_passport_5.jpg',\n",
       " 'Train_passport_50.jpg',\n",
       " 'Train_passport_52.jpg',\n",
       " 'Train_passport_53.jpg',\n",
       " 'Train_passport_54.jpg',\n",
       " 'Train_passport_56.jpg',\n",
       " 'Train_passport_58.jpg',\n",
       " 'Train_passport_59.jpg',\n",
       " 'Train_passport_6.jpg',\n",
       " 'Train_passport_60.jpg',\n",
       " 'Train_passport_7.jpg',\n",
       " 'Train_passport_8.jpg',\n",
       " 'Train_passport_9.jpg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dir='C:/Users/IBM_ADMIN/Desktop/DataFolder/'\n",
    "STANDARD_SIZE=(224,224) # Size of all Input Images\n",
    "num_classes=5 # Number of Classes the model needs to classify\n",
    "filenames = [img_dir+ f for f in os.listdir(img_dir)] # Names of the Input files present in Object Storage\n",
    "filenames= [f.split('/')[5] for f in filenames ]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Persistence and Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Configure Object Storage Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensure you name the variable containing Object Storage Credentials as credentials_1\n",
    "cos = ibm_boto3.client('s3',\n",
    "                    ibm_api_key_id=credentials_1['IBM_API_KEY_ID'],\n",
    "                    ibm_service_instance_id=credentials_1['IAM_SERVICE_ID'],\n",
    "                    ibm_auth_endpoint=credentials_1['IBM_AUTH_ENDPOINT'],\n",
    "                    config=Config(signature_version='oauth'),\n",
    "                    endpoint_url=credentials_1['ENDPOINT'])\n",
    "\n",
    "def get_file(filename):\n",
    "    '''Retrieve file from Cloud Object Storage'''\n",
    "    fileobject = cos.get_object(Bucket=credentials_1['BUCKET'], Key=filename)['Body']\n",
    "    return fileobject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Converting Data Format according to the backend used by Keras\n",
    "'''\n",
    "datagen=keras.preprocessing.image.ImageDataGenerator(data_format=K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_image(X):\n",
    "    '''Function to convert all Input Images to the STANDARD_SIZE and create Training Dataset\n",
    "    '''\n",
    "    for f in filenames:\n",
    "        #fobj=get_file(f)\n",
    "        #print(type(fobj))\n",
    "        img= PIL.Image.open(f)\n",
    "        img = img.resize(STANDARD_SIZE)\n",
    "        img=np.array(img)\n",
    "        X.append(img)\n",
    "        #print(X_train)\n",
    "    #print(len(X_train))\n",
    "    return X\n",
    "\n",
    "def convert_to_label():\n",
    "    '''Function to Append Labels to Training Data\n",
    "    '''\n",
    "    y=[]\n",
    "    for f in filenames:\n",
    "        y.append(f.split(\"_\")[0])\n",
    "    labelencoder_y = LabelEncoder()\n",
    "    y_temp= labelencoder_y.fit_transform(y)\n",
    "    #print(y_train_temp)\n",
    "    y_temp=np_utils.to_categorical(y_train_temp, num_classes)\n",
    "    #print(type(y_train_temp))\n",
    "    return y_temp\n",
    "#convert_to_label(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### VGG16 Model ###\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "###################################################################\n",
      "\n",
      "\n",
      "### Tweaked VGG16 Model ###\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5005      \n",
      "=================================================================\n",
      "Total params: 134,265,549\n",
      "Trainable params: 5,005\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n",
      "###################################################################\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = keras.applications.vgg16.VGG16() # Keras Functional API\n",
    "print(\"### VGG16 Model ###\")\n",
    "vgg16_model.summary()\n",
    "print(\"###################################################################\")\n",
    "print(\"\\n\")\n",
    "model = Sequential() #Iterate over the functional layers and add it as a stack\n",
    "for layer in vgg16_model.layers:\n",
    "    model.add(layer)\n",
    "model.layers.pop() # We don't want 1000 classes, so remove the last layer\n",
    "\n",
    "for layer in model.layers: #Since the model is already trained with certain weights, we dont want to change it. Let it be the same\n",
    "    layer.trainable = False\n",
    "\n",
    "model.add(Dense(num_classes, activation='sigmoid')) # Add the last layer\n",
    "\n",
    "print(\"### Tweaked VGG16 Model ###\")\n",
    "model.summary()\n",
    "print(\"###################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the Model built above\n",
    "model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Test_cheque_4.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-8dc1684ec47d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert_to_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# ndarray of Training Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert_to_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-ae2458dbb1d3>\u001b[0m in \u001b[0;36mconvert_to_image\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m#fobj=get_file(f)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m#print(type(fobj))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTANDARD_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2529\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2530\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2531\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Test_cheque_4.jpg'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Prepare Training Data to be fed into the Model\n",
    "'''\n",
    "X_train= []\n",
    "y_train= []\n",
    "X_train=np.array(convert_to_image(X_train)) # ndarray of Training Data\n",
    "y_train=np.array(convert_to_label(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5/5 [==============================] - 94s 19s/step - loss: 1.6069 - acc: 0.1200\n",
      "Epoch 2/5\n",
      "1/5 [=====>........................] - ETA: 1:15 - loss: 1.6015 - acc: 0.6000"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train your model\n",
    "'''\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=5),\n",
    "                    steps_per_epoch=5, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save('acc94final.h5') \n",
    "from keras.models import load_model\n",
    "model = load_model('acc94final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_batches, steps=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print(y_train)\n",
    "#y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "#y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
